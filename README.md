# Quantam-Enhanced
Here's your GitHub repository description (the short one-liner):

> Emotion-aware autonomous vehicle framework that detects pedestrian facial emotions in real-time using CNN (MobileNetV2) and adapts vehicle speed and trajectory via LSTM-based prediction and quantum-inspired decision logic â€” trained on FER-2013 and PIE datasets.

About:

> *Real-time pedestrian safety system for autonomous vehicles. Classifies pedestrian emotions (happy, sad, confused, distracted, angry) from live video using a fine-tuned MobileNetV2 model, maps emotional states to vehicle actions (proceed / slow / brake), and predicts trajectories using LSTM. Quantum-inspired superposition logic handles ambiguous or overlapping emotional detections. Achieves 86% emotion classification accuracy with under 100ms inference time.*
